# HENet
## resnet_fusion.py

This code is an implementation of the ResNet (Residual Network) model architectures for deep learning. The ResNet model is a type of convolutional neural network that uses shortcut connections to jump over some layers, allowing it to have very deep networks.

### Features

1. Pretrained models: The code can download pretrained models for different variants of ResNet from URLs provided by PyTorch.

2. Customizable parameters: Users can specify the type of block used (Basic Block or Bottleneck), the number of layers, whether to replace stride with dilation, and many more parameters when creating a model.

3. Different ResNet architectures supported: These include ResNet18, ResNet34, ResNet50, ResNet101, ResNet152, ResNeXt50_32x4d, ResNeXt101_32x8d, Wide ResNet-50-2, and Wide ResNet-101-2.

### Usage

The `resnet*` functions (for example, `resnet18`, `resnet50`) return a ResNet model pre-trained on ImageNet. You can use these functions in your code to easily create a ResNet model. 

For example, to create a ResNet50 model:

```python
model = resnet50(pretrained=True)
```

To use your own input data instead of pretrained weights, set `pretrained=False`.

```python
model = resnet50(pretrained=False)
```

Remember to install the necessary dependencies such as PyTorch before running the code.

Please note that this code does not handle image preprocessing or training loop, you have to write your own script to feed the images into the model and train it.


## Label.ipynb

This notebook contains code for generating labels for medical images. Here is an overview of the different sections in the notebook:

1. **Mask Information**: In this section, the code reads mask images and calculates information such as voxel counts and volumes for different classes (l1 and l2).

2. **Label Generation**: This section generates three labels (label1, label2, and label3) based on certain conditions related to the differences in volume between pre- and post-processed masks.

3. **Clinical and radiological Data**: The code reads clinical and radiological data from a CSV file and performs some preprocessing.

4. **Masks Transformation**: This section transforms the mask images by removing unnecessary classes.

5. **Generate 2.5D Data**: In this section, the code generates 2.5D data by combining multiple image slices together. It creates a cohort by joining the generated data with the clinical data.

6. **Exporting Data**: Finally, the code exports the generated data into text files for training and validation purposes.

## HENet Model.ipynb
This notebook contains the code for training a model using the HENet architecture. The parameters are set as follows:

1. **save_dir**: The directory to save the trained models.
2. **train_f**: The file path for the train features.
3. **val_f**: The file path for the two external data sets’ features.
4. **labels_f**: The file path for the labels.

## 2D Model.ipynb
This notebook contains the code for training a model using the 2D architecture. The parameters are set as follows:

1. **save_dir**: The directory to save the trained models.
2. **train_f**: The file path for the train features.
3. **val_f**: The file path for the two external data sets’ features.
4. **labels_f**: The file path for the labels.

## Grad-CAM.ipynb
This notebook contains the code for generating Grad-CAM visualizations. The parameters are set as follows:

1. **root**: The root directory.
2. **save_dir**: The directory to save the generated visualizations.
3. **model**: The model used for Grad-CAM.
4. **transformer**: The transformer object.
5. **device**: The device used for computation.
6. **target_layer**: The target layer for Grad-CAM visualization.
The Grad-CAM visualizations are generated by iterating over the samples and applying the Grad-CAM algorithm using the specified parameters. The resulting visualizations are then saved in the specified save_dir.


