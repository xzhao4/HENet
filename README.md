# HENet

## Label.ipynb

This notebook contains code for generating labels for medical images. Here is an overview of the different sections in the notebook:

1. **Mask Information**: In this section, the code reads mask images and calculates information such as voxel counts and volumes for different classes (l1 and l2).

2. **Label Generation**: This section generates three labels (label1, label2, and label3) based on certain conditions related to the differences in volume between pre- and post-processed masks.

3. **Clinical and radiological Data**: The code reads clinical and radiological data from a CSV file and performs some preprocessing.

4. **Masks Transformation**: This section transforms the mask images by removing unnecessary classes.

5. **Generate 2.5D Data**: In this section, the code generates 2.5D data by combining multiple image slices together. It creates a cohort by joining the generated data with the clinical data.

6. **Exporting Data**: Finally, the code exports the generated data into text files for training and validation purposes.

## HENet Model.ipynb
This notebook contains the code for training a model using the HENet architecture. The parameters are set as follows:

1. **save_dir**: The directory to save the trained models.
2. **train_f**: The file path for the train features.
3. **val_f**: The file path for the two external data sets’ features.
4. **labels_f**: The file path for the labels.

## 2D Model.ipynb
This notebook contains the code for training a model using the 2D architecture. The parameters are set as follows:

1. **save_dir**: The directory to save the trained models.
2. **train_f**: The file path for the train features.
3. **val_f**: The file path for the two external data sets’ features.
4. **labels_f**: The file path for the labels.

## Grad-CAM.ipynb
This notebook contains the code for generating Grad-CAM visualizations. The parameters are set as follows:

1. **root**: The root directory.
2. **save_dir**: The directory to save the generated visualizations.
3. **model**: The model used for Grad-CAM.
4. **transformer**: The transformer object.
5. **device**: The device used for computation.
6. **target_layer**: The target layer for Grad-CAM visualization.
The Grad-CAM visualizations are generated by iterating over the samples and applying the Grad-CAM algorithm using the specified parameters. The resulting visualizations are then saved in the specified save_dir.
